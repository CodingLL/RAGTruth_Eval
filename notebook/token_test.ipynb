{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hallucination_check_prompt(task_type, source_info, response):\n",
    "    if task_type == 'Summary':\n",
    "        article = source_info\n",
    "        prompt = 'Below is the original news:\\n'\n",
    "        prompt += f'{article}'+'\\n'\n",
    "        prompt += 'Below is a summary of the news:\\n'\n",
    "        prompt += f'{response}'+'\\n'\n",
    "        prompt += 'Your task is to identify and label any hallucinated statements in the summary that are unsupported or contradicted by the original news. '\n",
    "    elif task_type == 'Data2txt':\n",
    "        business_info = source_info\n",
    "        prompt = 'Below is a structured data in the JSON format:\\n'\n",
    "        prompt += f'{business_info}'+'\\n'\n",
    "        prompt += 'Below is an overview article written in accordance with the structured data:\\n'\n",
    "        prompt += f'{response}'+'\\n'\n",
    "        prompt += 'Your task is to identify and label any hallucinated statements in the overview that are unsupported or contradicted by the structured data. '\n",
    "    elif task_type == 'QA':\n",
    "        question, passages = source_info['question'], source_info['passages']\n",
    "        prompt = 'Below is a question:\\n'\n",
    "        prompt += f'{question}'+'\\n\\n'\n",
    "        prompt += 'Below are related passages:\\n'\n",
    "        prompt += f'{passages}'+'\\n'\n",
    "        prompt += 'Below is an answer:\\n'\n",
    "        prompt += f'{response}'+'\\n\\n'\n",
    "        prompt += 'Your task is to identify and label any hallucinated statements in the answer that are unsupported or contradicted by the passages. '\n",
    "    prompt += 'Then, compile the labeled hallucinated spans into a JSON list, with each list item representing a separate hallucinated span.\\n'\n",
    "    prompt += 'Output:'\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Below is a question:\\nWhat is Trump\\n\\nBelow are related passages:\\npassage1: Trump is overweight.\\npassage2: Trump is handsome.\\nBelow is an answer:\\nAccording to three passages, Trump is a dog.\\n\\nYour task is to identify and label any hallucinated statements in the answer that are unsupported or contradicted by the passages. Then, compile the labeled hallucinated spans into a JSON list, with each list item representing a separate hallucinated span.\\nOutput:'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_info = {'question': 'What is Trump', 'passages': 'passage1: Trump is overweight.\\npassage2: Trump is handsome.'}\n",
    "response = 'According to three passages, Trump is a dog.'\n",
    "input_str = hallucination_check_prompt('QA', source_info, response)\n",
    "input_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = InferenceClient(model='http://localhost:8346', timeout=100)\n",
    "output = client.text_generation(input_str, \n",
    "                                max_new_tokens=512, \n",
    "                                stream=False,\n",
    "                                do_sample=True,\n",
    "                                temperature=0.1,\n",
    "                                details=True\n",
    "                                )\n",
    "output_details = [{'id': i.id, 'text': i.text, 'logprob': np.exp(i.logprob), 'special': i.special} for i in output.details.tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextGenerationResponse(generated_text=' [\"According to three passages, Trump is a dog.\"]', details=Details(finish_reason=<FinishReason.EndOfSequenceToken: 'eos_token'>, generated_tokens=15, seed=11784489630023641976, prefill=[], tokens=[Token(id=6796, text=' [\"', logprob=0.0, special=False), Token(id=7504, text='Acc', logprob=-0.018188477, special=False), Token(id=3278, text='ording', logprob=0.0, special=False), Token(id=304, text=' to', logprob=0.0, special=False), Token(id=2211, text=' three', logprob=0.0, special=False), Token(id=1209, text=' pass', logprob=0.0, special=False), Token(id=1179, text='ages', logprob=0.0, special=False), Token(id=29892, text=',', logprob=0.0, special=False), Token(id=27504, text=' Trump', logprob=0.0, special=False), Token(id=338, text=' is', logprob=0.0, special=False), Token(id=263, text=' a', logprob=0.0, special=False), Token(id=11203, text=' dog', logprob=0.0, special=False), Token(id=1213, text='.\"', logprob=0.0, special=False), Token(id=29962, text=']', logprob=0.0, special=False), Token(id=2, text='</s>', logprob=0.0, special=True)], best_of_sequences=None))"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 6796, 'text': ' [\"', 'logprob': 1.0, 'special': False},\n",
       " {'id': 7504, 'text': 'Acc', 'logprob': 0.9819759350372468, 'special': False},\n",
       " {'id': 3278, 'text': 'ording', 'logprob': 1.0, 'special': False},\n",
       " {'id': 304, 'text': ' to', 'logprob': 1.0, 'special': False},\n",
       " {'id': 2211, 'text': ' three', 'logprob': 1.0, 'special': False},\n",
       " {'id': 1209, 'text': ' pass', 'logprob': 1.0, 'special': False},\n",
       " {'id': 1179, 'text': 'ages', 'logprob': 1.0, 'special': False},\n",
       " {'id': 29892, 'text': ',', 'logprob': 1.0, 'special': False},\n",
       " {'id': 27504, 'text': ' Trump', 'logprob': 1.0, 'special': False},\n",
       " {'id': 338, 'text': ' is', 'logprob': 1.0, 'special': False},\n",
       " {'id': 263, 'text': ' a', 'logprob': 1.0, 'special': False},\n",
       " {'id': 11203, 'text': ' dog', 'logprob': 1.0, 'special': False},\n",
       " {'id': 1213, 'text': '.\"', 'logprob': 1.0, 'special': False},\n",
       " {'id': 29962, 'text': ']', 'logprob': 1.0, 'special': False},\n",
       " {'id': 2, 'text': '</s>', 'logprob': 1.0, 'special': True}]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
